{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70628a9",
   "metadata": {},
   "source": [
    "### Либы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ebc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66014777",
   "metadata": {},
   "source": [
    "### Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c007c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('dataset/images.npy')\n",
    "labels = np.load('dataset/labels.npy')\n",
    "images_sub = np.load('dataset/images_sub.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ee5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализуем наши датасетики\n",
    "images = images.astype('float32') / 255.0\n",
    "images_sub = images_sub.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1ebaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cat = to_categorical(labels, num_classes=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02631288",
   "metadata": {},
   "source": [
    "### Создаём рабочие датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62036c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, labels_cat, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4dc4f",
   "metadata": {},
   "source": [
    "### Готовим аугментацию чтоб не переобучиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5565ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7fbcf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee4c7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow(X_train, y_train, batch_size=64)\n",
    "val_gen = val_datagen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944bb9e",
   "metadata": {},
   "source": [
    "### Будем использовать CNN\n",
    "\n",
    "> ChatGPT подсказала, как можно её улучшить для большего эффекта 🔥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05c7147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pycode25\\kaggle-captcha\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(48,48,3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(26, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af970a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c93d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# колбэки - помогают повысить эффективность CNN\n",
    "lr_reduce = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', patience=3, factor=0.5, min_lr=1e-5, verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy', patience=7, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b94678",
   "metadata": {},
   "source": [
    "### Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07e243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pycode25\\kaggle-captcha\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 942ms/step - accuracy: 0.0459 - loss: 3.4513 - val_accuracy: 0.0385 - val_loss: 3.2926 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 951ms/step - accuracy: 0.0775 - loss: 3.1583 - val_accuracy: 0.1195 - val_loss: 3.0217 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 946ms/step - accuracy: 0.1306 - loss: 2.9332 - val_accuracy: 0.1840 - val_loss: 2.6874 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 964ms/step - accuracy: 0.1951 - loss: 2.6387 - val_accuracy: 0.2835 - val_loss: 2.3913 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 942ms/step - accuracy: 0.2997 - loss: 2.2320 - val_accuracy: 0.4375 - val_loss: 1.7627 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 949ms/step - accuracy: 0.4130 - loss: 1.8236 - val_accuracy: 0.5380 - val_loss: 1.4384 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 914ms/step - accuracy: 0.5017 - loss: 1.5340 - val_accuracy: 0.6960 - val_loss: 1.0101 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 944ms/step - accuracy: 0.5786 - loss: 1.3026 - val_accuracy: 0.7100 - val_loss: 0.9205 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 950ms/step - accuracy: 0.6315 - loss: 1.1524 - val_accuracy: 0.7675 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 950ms/step - accuracy: 0.6607 - loss: 1.0482 - val_accuracy: 0.8085 - val_loss: 0.6219 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 976ms/step - accuracy: 0.6849 - loss: 0.9680 - val_accuracy: 0.8255 - val_loss: 0.5720 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 974ms/step - accuracy: 0.7122 - loss: 0.8878 - val_accuracy: 0.8115 - val_loss: 0.5991 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 967ms/step - accuracy: 0.7348 - loss: 0.8278 - val_accuracy: 0.8505 - val_loss: 0.4934 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 986ms/step - accuracy: 0.7460 - loss: 0.7760 - val_accuracy: 0.8620 - val_loss: 0.4471 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 964ms/step - accuracy: 0.7600 - loss: 0.7439 - val_accuracy: 0.8585 - val_loss: 0.4401 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 993ms/step - accuracy: 0.7678 - loss: 0.7253 - val_accuracy: 0.8860 - val_loss: 0.3682 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 955ms/step - accuracy: 0.7830 - loss: 0.6775 - val_accuracy: 0.8570 - val_loss: 0.4340 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 996ms/step - accuracy: 0.7800 - loss: 0.6785 - val_accuracy: 0.8995 - val_loss: 0.3444 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 957ms/step - accuracy: 0.7906 - loss: 0.6430 - val_accuracy: 0.8275 - val_loss: 0.6452 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 989ms/step - accuracy: 0.7997 - loss: 0.6220 - val_accuracy: 0.9020 - val_loss: 0.3060 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 966ms/step - accuracy: 0.8081 - loss: 0.5939 - val_accuracy: 0.8950 - val_loss: 0.3622 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 938ms/step - accuracy: 0.8196 - loss: 0.5654 - val_accuracy: 0.9085 - val_loss: 0.3009 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 943ms/step - accuracy: 0.8135 - loss: 0.5836 - val_accuracy: 0.9040 - val_loss: 0.3249 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 944ms/step - accuracy: 0.8163 - loss: 0.5642 - val_accuracy: 0.9060 - val_loss: 0.3255 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936ms/step - accuracy: 0.8266 - loss: 0.5314\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 954ms/step - accuracy: 0.8266 - loss: 0.5314 - val_accuracy: 0.9080 - val_loss: 0.2869 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 938ms/step - accuracy: 0.8417 - loss: 0.4859 - val_accuracy: 0.9145 - val_loss: 0.2718 - learning_rate: 5.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 964ms/step - accuracy: 0.8461 - loss: 0.4767 - val_accuracy: 0.9335 - val_loss: 0.2242 - learning_rate: 5.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 938ms/step - accuracy: 0.8548 - loss: 0.4449 - val_accuracy: 0.9265 - val_loss: 0.2502 - learning_rate: 5.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 958ms/step - accuracy: 0.8537 - loss: 0.4508 - val_accuracy: 0.9325 - val_loss: 0.2220 - learning_rate: 5.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927ms/step - accuracy: 0.8537 - loss: 0.4478\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 945ms/step - accuracy: 0.8537 - loss: 0.4478 - val_accuracy: 0.9330 - val_loss: 0.2225 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29f49f058b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_gen,\n",
    "    epochs=30,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[lr_reduce, early_stop],\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281ff1f",
   "metadata": {},
   "source": [
    "### Предскажем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87fd2d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 612ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_probs = model.predict(images_sub, batch_size=256)\n",
    "pred_classes = np.argmax(pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39fb3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': np.arange(len(pred_classes)),\n",
    "    'Category': pred_classes\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
